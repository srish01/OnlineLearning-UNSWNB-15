{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Classification Analysis of Static Classifiers \n",
    "\n",
    "This script perform the experiments for static analysis of classifiers on the UNSW_NB15 dataset. These experiments are used to form a baseline for the best case scenario when all of the training data are available to learn from when they are available. We use the off-the-shelf classifiers from [Sklearn](https://scikit-learn.org/) to benchmark. We extend the previous results from the author's that presented in some of their previous work.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy as sp\n",
    "import pandas as pd \n",
    "import matplotlib.pylab as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# load static classifiers \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the global variables and paths that will be used throughout this document \n",
    "data_path = '../data/'      # path to the dataset (should be ../data/)\n",
    "K = 5                       # number of randomized trials to run \n",
    "binary_classes = True       # do you want to run classifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe2dataset(df, training = False, label_dict = {}): \n",
    "    \"\"\"\n",
    "    X, y, label_dict = dataframe2dataset(df, training = False, label_dict = {})\n",
    "    \"\"\"\n",
    "\n",
    "    drop_cols = ['id', 'proto', 'service', 'state', 'attack_cat', 'label', 'is_sm_ips_ports']\n",
    "    df_feat = df.drop(drop_cols, axis = 1)\n",
    "    \n",
    "    X = df_feat.values\n",
    "    labels = df['attack_cat'].values\n",
    "    y = np.zeros((len(X),))\n",
    "    \n",
    "    if training: \n",
    "        uni_labels = np.unique(labels)\n",
    "        label_dict = {}\n",
    "        for lbl, n in zip(uni_labels, range(len(uni_labels))):\n",
    "            label_dict[lbl] = n\n",
    "            \n",
    "        # swap the index of the labels for normal and analysis to make the label of the normal \n",
    "        # samples be equal to one. this is a bit more standard than having the normal data \n",
    "        # be nonzero. \n",
    "        label_dict['Analysis'] = 6\n",
    "        label_dict['Normal'] = 0\n",
    "        \n",
    "    for n in range(len(y)): \n",
    "        y[n] = label_dict[labels[n]]\n",
    "        \n",
    "    return X, y, label_dict\n",
    "\n",
    "def calc_binary_results(y, yhat):\n",
    "    \"\"\"\n",
    "    tpr, tnr, fpr, fnr, f1s, acc, mcc = calc_binary_results(y, yhat)\n",
    "    \"\"\"\n",
    "    tp, tn, fp, fn = 0., 0., 0., 0.\n",
    "    for i in range(len(y)): \n",
    "        if y[i] == 1. and yhat[i] == 1.: \n",
    "            tp += 1.\n",
    "        elif y[i] == 0. and yhat[i] == 0.:\n",
    "            tn += 1.\n",
    "        elif y[i] == 0. and yhat[i] == 1.: \n",
    "            fp += 1.\n",
    "        elif y[i] == 1. and yhat[i] == 0.: \n",
    "            fn += 1.\n",
    "        else: \n",
    "            print('Should not be here.')\n",
    "            \n",
    "    tpr = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fp)\n",
    "    fpr = fp/(fp+tn)\n",
    "    fnr = fn/(fn+tp)\n",
    "    f1s = 2*tp/(2*tp+tn+tp)\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    mcc = (tp*tn-fp*fn)/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    \n",
    "    return tpr, tnr, fpr, fnr, f1s, acc, mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse out the training and testing data\n",
    "df_tr = pd.read_csv(data_path + 'UNSW_NB15_training-set.csv')\n",
    "df_te = pd.read_csv(data_path + 'UNSW_NB15_testing-set.csv')\n",
    "\n",
    "Xtr, ytr, label_dict = dataframe2dataset(df_tr, training=True)\n",
    "Xte, yte, _ = dataframe2dataset(df_te, training=False, label_dict=label_dict)\n",
    "\n",
    "scaler = StandardScaler().fit(Xtr)\n",
    "Xtr = scaler.transform(Xtr)\n",
    "Xte = scaler.transform(Xte)\n",
    "\n",
    "if binary_classes: \n",
    "    i, j = np.where(ytr!=0)[0], np.where(yte!=0)[0]\n",
    "    ytr[i] = 1.\n",
    "    yte[j] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running naive Bayes\n",
      "Running CART\n",
      "Running Adaboost\n",
      "Running RandomForest\n",
      "Running GradientBoosting\n",
      "Running LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gditzler/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/gditzler/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/gditzler/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/gditzler/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/gditzler/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=25, max_features=10),\n",
    "    AdaBoostClassifier(n_estimators=25),\n",
    "    GaussianNB()]\n",
    "\n",
    "classifiers = [GaussianNB(), \n",
    "               DecisionTreeClassifier(max_depth=5), \n",
    "               AdaBoostClassifier(), \n",
    "               RandomForestClassifier(max_depth=5, n_estimators=25, max_features=10), \n",
    "               GradientBoostingClassifier(), \n",
    "               LogisticRegression()\n",
    "              ]\n",
    "classifier_name = ['naive Bayes', 'CART', 'Adaboost', 'RandomForest', 'GradientBoosting', 'LogisticRegression']\n",
    "\n",
    "tprs, tnrs, fprs, fnrs, f1ss, accs, mccs = np.zeros((len(classifiers),)), np.zeros((len(classifiers),)), np.zeros((len(classifiers),)), np.zeros((len(classifiers),)), np.zeros((len(classifiers),)), np.zeros((len(classifiers),)), np.zeros((len(classifiers),))\n",
    "\n",
    "n = 0\n",
    "for clf in classifiers:\n",
    "    print('Running ' + classifier_name[n])\n",
    "    for k in range(K): \n",
    "        clf_k = clf\n",
    "        j = np.random.randint(0, len(ytr), len(ytr))\n",
    "        yhat = clf_k.fit(Xtr[j], ytr[j]).predict(Xte)\n",
    "        tpr, tnr, fpr, fnr, f1s, acc, mcc = calc_binary_results(yte, yhat)\n",
    "        \n",
    "        tprs[n] += tpr\n",
    "        tnrs[n] += tnr\n",
    "        fprs[n] += fpr\n",
    "        fnrs[n] += fnr\n",
    "        f1ss[n] += f1s\n",
    "        accs[n] += acc\n",
    "        mccs[n] += mcc\n",
    "        \n",
    "    n += 1\n",
    "\n",
    "tprs, tnrs, fprs, fnrs, f1ss, accs, mccs = tprs/K, tnrs/K, fprs/K, fnrs/K, f1ss/K, accs/K, mccs/K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.65813553, 0.99423365, 0.96920939, 0.99969999, 0.98619077,\n",
       "        0.94124239]),\n",
       " array([0.84864865, 0.59869189, 0.70718919, 0.57863243, 0.69067027,\n",
       "        0.57061622]),\n",
       " array([0.15135135, 0.40130811, 0.29281081, 0.42136757, 0.30932973,\n",
       "        0.42938378]),\n",
       " array([3.41864467e-01, 5.76634607e-03, 3.07906115e-02, 3.00008824e-04,\n",
       "        1.38092297e-02, 5.87576105e-02]),\n",
       " array([0.49347569, 0.57282573, 0.55624348, 0.57596709, 0.55997037,\n",
       "        0.57227258]),\n",
       " array([0.74375213, 0.81647719, 0.85145751, 0.81047223, 0.85338386,\n",
       "        0.77468299]),\n",
       " array([0.50922656, 0.66271292, 0.71301259, 0.65569315, 0.72298866,\n",
       "        0.56189136]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tprs, tnrs, fprs, fnrs, f1ss, accs, mccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
